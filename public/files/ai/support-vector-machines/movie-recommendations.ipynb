{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd219f5b-9c65-4402-94f0-5e1933cc040f"
    }
   },
   "source": [
    "$$\n",
    "\\renewcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\b}{\\mathbf}\n",
    "\\renewcommand{\\u}{\\mathbf{u}}\n",
    "\\renewcommand{\\v}{\\mathbf{v}}\n",
    "$$\n",
    "\n",
    "# Movie Recommendations\n",
    "\n",
    "| user  | Moonlight | The Shape of Water | Frozen | Moana |\n",
    "| ----- | --------- | ------------------ | ------ | ----- |\n",
    "| Alice | 5         | 4                  | 1      |       |\n",
    "| Bob   |           | 5                  |        | 2     |\n",
    "| Carol |           |                    |        | 5     |\n",
    "| David |           |                    | 5      | 5     |\n",
    "| Eve   | 5         | 4                  |        |       |\n",
    "\n",
    "What movie should I recommend to Bob?\n",
    "Will Carol like Frozen?\n",
    "\n",
    "**Goal**: Fill in entries of the \"rating matrix\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "417fa0e4-6c70-4b9f-a42c-876215db961d"
    }
   },
   "source": [
    "# Problem Setup\n",
    "\n",
    "Let's formalize this as a machine learning problem. To make it concrete, let's load some data and see what it looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>Jungle2Jungle (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>Apocalypse Now (1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>942</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>Stargate (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>942</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Willy Wonka and the Chocolate Factory (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>942</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Rumble in the Bronx (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>942</td>\n",
       "      <td>731</td>\n",
       "      <td>4</td>\n",
       "      <td>Dave (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>942</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating                                         title\n",
       "2070        0       242       1                          Jungle2Jungle (1997)\n",
       "2175        0        73       1           Faster Pussycat! Kill! Kill! (1965)\n",
       "984         0       101       2                        Aristocats, The (1970)\n",
       "2400        0       236       2                          Jerry Maguire (1996)\n",
       "4364        0       179       3                         Apocalypse Now (1979)\n",
       "...       ...       ...     ...                                           ...\n",
       "1373      942        61       3                               Stargate (1994)\n",
       "724       942       150       4  Willy Wonka and the Chocolate Factory (1971)\n",
       "1883      942        23       4                    Rumble in the Bronx (1995)\n",
       "3403      942       731       4                                   Dave (1993)\n",
       "1851      942        11       5                    Usual Suspects, The (1995)\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Load train and test data\n",
    "data = scipy.io.loadmat('movies.mat')\n",
    "\n",
    "titles = [t[0] for t in data['movieData']['title'][0, 0].ravel()]\n",
    "\n",
    "for x, y in data.items():\n",
    "    if isinstance(y, (np.ndarray)) and len(y) == 1:\n",
    "        data[x] = y.item()\n",
    "    elif isinstance(y, (np.ndarray)):\n",
    "        data[x] = y.ravel()\n",
    "\n",
    "nUsers = data['nUsers']\n",
    "nMovies = data['nMovies']\n",
    "userData = data['userData']\n",
    "movieData = data['movieData']\n",
    "\n",
    "train_user = data['train_user']-1   # matlab 1-index correction\n",
    "train_movie = data['train_movie']-1  # matlab 1-index correction\n",
    "train_rating = data['train_rating']\n",
    "\n",
    "valid_user = data['valid_user']-1   # matlab 1-index correction\n",
    "valid_movie = data['valid_movie']-1  # matlab 1-index correction\n",
    "valid_rating = data['valid_rating']\n",
    "\n",
    "test_user = data['test_user']-1    # matlab 1-index correction\n",
    "test_movie = data['test_movie']-1   # matlab 1-index correction\n",
    "\n",
    "\n",
    "# Create a pandas data frame for training data to facilitate\n",
    "# visualization and inspection\n",
    "\n",
    "train_title = [titles[i] for i in train_movie]\n",
    "\n",
    "train_data = pd.DataFrame(data={'user_id': train_user,\n",
    "                                'movie_id': train_movie,\n",
    "                                'rating': train_rating,\n",
    "                                'title': train_title},\n",
    "                          columns=['user_id', 'movie_id', 'rating', 'title'])\n",
    "\n",
    "# subsample to 5000 rows to more easily see a small sampling of ratings for each user\n",
    "train_data = train_data[:5000]\n",
    "\n",
    "# sort by user\n",
    "train_data = train_data.sort_values(by=['user_id', 'rating'])\n",
    "\n",
    "display(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534"
    }
   },
   "source": [
    "## Training Data\n",
    "\n",
    "As we can see, the training data presents observed entries of the \"ratings\" matrix as list of triples $(i_k, j_k, r_k)$ where\n",
    "\n",
    "- $i_k$ is the user index of $k$th rating\n",
    "- $j_k$ is the movie index of $k$th rating\n",
    "- $r_k$ is the value of $k$th rating (1-5)\n",
    "\n",
    "In our code we will store the entries of the tuples in three separate 1d arrays of the same length, so the $k$th rating is represented by the values `train_user[k]`, `train_movie[k]`, and `train_rating[k]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "33f22eff-c565-4acc-bd8d-5d40678cb1e5"
    }
   },
   "source": [
    "## Problem Formulation\n",
    "\n",
    "Now, let's formulate the problem mathematically. Suppose there are $m$ users and $n$ movies.\n",
    "Let $R$ be the $m \\times n$ \"rating\" matrix, where $R_{ij}$ is the (possibly unknown) rating for user $i$ on movie $j$.\n",
    "\n",
    "Our training data gives us some of the entries of the rating matrix. Our goal\n",
    "is to learn a parametric model to predict entries that we don't observe.\n",
    "\n",
    "#### But Where are the Features?\n",
    "\n",
    "What sort of predictive model can we use for entries of $R$?\n",
    "\n",
    "In past learning problems we had _feature vectors_ and we learned _weight vectors_ to make predictions (using dot products).\n",
    "\n",
    "Now we do not have feature vectors. What should we do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ad3301d3-5e9b-4f82-8180-9410aa5fd885"
    }
   },
   "source": [
    "## Matrix Factorization Model\n",
    "\n",
    "Our solution is to **learn weight vectors for both users and movies**.\n",
    "\n",
    "Let $u_i$ in $R^d$ be the weight vector for user $i$ and $v_j$ in $R^d$ be the weight vector for movie $j$. Then we can predict the rating for user $i$ on movie $j$ as:\n",
    "\n",
    "$$\n",
    "H_{ij} =u_i^T v_j\n",
    "$$\n",
    "\n",
    "Our goal is to learn weight vectors for every user and movie so that $R_{ij} \\approx H_{ij}$ for those entries of the rating matrix that we observe.\n",
    "\n",
    "**Problem statement**:\n",
    "Given observed entries of the rating matrix presented as triples $(i_k, j_k, r_k)$ for $k=1, \\ldots, n_{\\text{train}}$, find weight vectors $\\mathbf{u_i}$ for each user $i$ and $\\mathbf{v}_j$ for each movie $j$ such that:\n",
    "\n",
    "$$\n",
    "r_k \\approx \\mathbf{u_{i_k}}^T \\mathbf{v_{j_k}}, \\quad k=1, 2, \\ldots, n_{\\text{train}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f68ec3c-1530-4569-abd9-306b981a638b"
    }
   },
   "source": [
    "## Why is This Called Matrix Factorization?\n",
    "\n",
    "- Place the user weight vectors $u_i$ into the rows of a matrix\n",
    "  $U$ and the movie feature vectors $v_j$ into\n",
    "  the rows of a matrix $V$\n",
    "\n",
    "  $$\n",
    "  \\newcommand{\\line}{-}\n",
    "  U =\n",
    "      \\begin{bmatrix}\n",
    "          \\line u_1^T \\line \\\\\n",
    "          \\line u_2^T \\line \\\\\n",
    "          \\ldots \\\\\n",
    "          \\line u_m^T \\line \\\\\n",
    "      \\end{bmatrix} \\text{in}\\ \\R^{m \\times d}\n",
    "  \\qquad\n",
    "  V =\n",
    "      \\begin{bmatrix}\n",
    "          \\line v_1^T \\line \\\\\n",
    "          \\line v_2^T \\line \\\\\n",
    "          \\ldots \\\\\n",
    "          \\line v_n^T \\line \\\\\n",
    "      \\end{bmatrix} \\text{in}\\ \\R^{n \\times d}\n",
    "  $$\n",
    "\n",
    "- Consider the product $U V^T$:\n",
    "\n",
    "  $$\n",
    "  \\boxed{\n",
    "      \\begin{array}{c}\n",
    "          \\\\\n",
    "          U \\\\\n",
    "          \\\\\n",
    "      \\end{array}\n",
    "      }\n",
    "  \\boxed{\n",
    "      \\begin{array}{c}\n",
    "          \\\\ \\\\ \\\\ V^T \\\\ \\\\ \\\\\n",
    "      \\end{array}\n",
    "      }\n",
    "  $$\n",
    "\n",
    "- It is easy to check that $(i,j)$ entry of $UV^T$ is equal to $u_i^T v_j$, which is our prediction for the $(i,j)$ entry of $R$\n",
    "\n",
    "- In other words, our model is that $R \\approx U V^T$ (a **factorization**\n",
    "  of $R$)\n",
    "\n",
    "- We choose $U$ and $V$ to get good predictions for those entries of\n",
    "  $R$ that we can observe. As long as we don't overfit, this gives us\n",
    "  power to generalize to entries we don't observe\n",
    "- The \"hidden dimension\" $d$ (the length of each weight vector) is a hyperparameter\n",
    "  that must be tuned with hold-out data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c743c2d0-2dc4-4101-881c-01053255f632"
    }
   },
   "source": [
    "## Your Job: Solve the Learning Problem\n",
    "\n",
    "- Formulate a squared error cost function corresponding to the problem statement above.\n",
    "- Add regularization for _every_ user weight vector $u_i$ and movie weight vector $v_j$ to get a regularized cost function\n",
    "- Write down the partial derivatives of your regularized cost function with\n",
    "  respect to the entries of $u_i$ and $v_j$\n",
    "- Plug the partial derivatives into stochastic gradient descent (SGD)\n",
    "  and write down the update rule\n",
    "- Implement SGD\n",
    "- Tune parameters (e.g., dimension $d$, regularization parameter) get good performance on the validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "25aa92a1-20c9-4206-9133-ab31f96cb321"
    }
   },
   "source": [
    "## Logistics\n",
    "\n",
    "- Submit predictions on test set\n",
    "- Evaluation: root-mean squared error (RMSE) on test set\n",
    "\n",
    "  $$ \\text{RMSE} = \\sqrt{\\frac{1}{n_{\\text{test}}}\\sum_{(i,j) \\in \\text{test set}} (H_{ij} - R_{ij})^2}$$\n",
    "\n",
    "- Your grade:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| RMSE    | grade |\n",
    "| ------- | ----- | --- |\n",
    "| <= 1.0  | 80%   |\n",
    "| <= 0.97 | 90%   |\n",
    "| <= 0.95 | 95%   |\n",
    "| <= 0.94 | 100%  |     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "597ff142-4663-4ddb-bc6f-7b71e1127cc0"
    }
   },
   "source": [
    "## (Review on your own) Model Extension: Add Biases\n",
    "\n",
    "To get really great performance, consider this extended model for a predicted rating:\n",
    "\n",
    "$$\n",
    "H_{ij} = \\mu + a_i + b_j + u_i^T v_j\n",
    "$$\n",
    "\n",
    "This adds several terms to the prediction for user $i$ on movie $j$:\n",
    "\n",
    "- $\\mu$ is an overall baseline rating. For example, the overall average rating of all users\n",
    "  on all movies may be $\\mu = 3.3$\n",
    "- $a_i$ is a user-specific adjustment or \"bias\". For example, perhaps Alice\n",
    "  really loves movies and gives them all high ratings. Then, her bias\n",
    "  might be $a_i = +0.4$. But Bob is hard to please, so his bias is $a_i = -0.7$.\n",
    "- $b_j$ is a movie-specific bias. For example, perhaps Inside Out is universally\n",
    "  loved, so its bias is $b_j = +0.7$. A really bad movie would have a negative bias.\n",
    "\n",
    "The set of parameters of this model includes:\n",
    "\n",
    "- $\\mu$\n",
    "- $a_i$, $i=1,\\ldots, m$\n",
    "- $b_j$, $j=1,\\ldots, n$\n",
    "- $u_i \\in \\R^d$, $i=1,\\ldots, m$\n",
    "- $v_j \\in \\R^d$, $j=1,\\ldots, n$\n",
    "\n",
    "To learn these parameters, derive partial derivatives of the regularized\n",
    "cost function with respect to _all_ of the above parameters, and update\n",
    "them all within your stochastic gradient descent loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "[Matrix Factorization Techniques for Recommender\n",
    "Systems](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    "by Yehuda Koren, Robert Bell and Chris Volinsky\n",
    "\n",
    "- Authors were on the winning team of Netflix prize\n",
    "\n",
    "- Paper includes algorithms---but beware different notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Familiarize Yourself With Variables\n",
    "\n",
    "Here are the variables we populated while loading the data above --- make sure you run that cell first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Metadata\n",
    "#\n",
    "#     nUsers     # of users\n",
    "#     nMovies    # of movies\n",
    "#     titles     list of movie titles\n",
    "#\n",
    "#\n",
    "# 2) Training data (60K ratings). This consists of three 1d arrays,\n",
    "#    each of length 60K:\n",
    "#\n",
    "#      train_user, train_movie, train_rating\n",
    "#\n",
    "#    The entries specify the ratings:\n",
    "#\n",
    "#      train_user[k]    user index  of kth rating\n",
    "#      train_movie[k]   movie index of kth rating\n",
    "#      train_rating[k]  value (1-5) of kth rating\n",
    "#\n",
    "# 2) Validation data (20K ratings). Three vectors of length 20K:\n",
    "#\n",
    "#      valid_user, valid_movie, valid_rating\n",
    "#\n",
    "#    Use this to evaluate your model and tune parameters.\n",
    "#\n",
    "# 3) Test set (20K user-movie pairs without ratings):\n",
    "#\n",
    "#      test_user, test_movie\n",
    "#\n",
    "#    You will create predictions for these pairs and submit them for\n",
    "#    grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Look at the Prediction Method\n",
    "\n",
    "To make things concrete, first take a look at the prediction method below. This is just a stub for now that returns the same value `mu` for every prediction. Later you will update this to make predictions given the weight vectors and biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "46a5a100-4e08-43e9-a313-ea1a0f06d149"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(h, r):\n",
    "    resid = h - r\n",
    "    cost = np.sqrt(np.mean(resid**2))\n",
    "    return cost\n",
    "\n",
    "\n",
    "def cost_function(ratings, user, movie, lambda_1, lambda_2):\n",
    "    errs = 0\n",
    "    for k, r_ix in enumerate(ratings):\n",
    "         errs += (r_ix - np.sum(np.dot(user[train_user[k]], movie[train_movie[k]]))) ** 2\n",
    "\n",
    "    norm_sqd = lambda a: np.linalg.norm(a) ** 2\n",
    "    return errs + lambda_1 * np.sum(np.apply_along_axis(norm_sqd, 1, movie)) + lambda_2 * np.sum(np.apply_along_axis(norm_sqd, 1, user))\n",
    "\n",
    "def predict(mu, user, movie):\n",
    "    '''\n",
    "    PREDICT Make predictions for user/movie pairs\n",
    "    Inputs: \n",
    "      model parameters\n",
    "      user               vector of users\n",
    "      movie              vector of movies\n",
    "\n",
    "    Output:\n",
    "      predictions        vector of predictions\n",
    "    '''\n",
    "    \n",
    "    L = len(user)\n",
    "    predictions = np.zeros(L)\n",
    "    for k, x in enumerate(user):\n",
    "      i = movie[k]\n",
    "      predictions[k] = mu + a[x] + b[i] + np.dot(U[x], V[i].T)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Learning and Validation\n",
    "\n",
    "Write code here to do the learning and validation. Stubs are provided. Make sure you derive the partial derivatives on paper before you try to code them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cost:  785159.3234562045\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################\n",
    "# Tunable parameters (you will add more)\n",
    "############################################\n",
    "\n",
    "nDims = 5\n",
    "\n",
    "lambda_1 = 0.1\n",
    "lambda_2 = 0.1\n",
    "lambda_3 = 10\n",
    "lambda_4 = 10\n",
    "\n",
    "############################################\n",
    "# Initialize parameters\n",
    "############################################\n",
    "\n",
    "mu = np.mean(train_rating)\n",
    "a = np.zeros(nUsers)\n",
    "b = np.zeros(nMovies)\n",
    "U = np.random.randn(nUsers, nDims) * .01  # User weights\n",
    "V = np.random.randn(nMovies, nDims) * .01  # Movie features\n",
    "\n",
    "############################################\n",
    "# Training and validation\n",
    "############################################\n",
    "\n",
    "alpha = 0.01\n",
    "iters = 150\n",
    "\n",
    "J_history = [0 for _ in range(iters)]\n",
    "\n",
    "for iter in range(iters):\n",
    "\n",
    "   for k, r_ix in enumerate(train_rating):\n",
    "      i, x = train_movie[k], train_user[k]\n",
    "      a_x = a[x]\n",
    "      b_i = b[i]\n",
    "      q_i = V[i]\n",
    "      p_x = U[x]\n",
    "\n",
    "      err = r_ix - (mu + a_x + b_i + np.dot(q_i, p_x))\n",
    "\n",
    "      a[x] = a_x - alpha * (-2 * err + 2 * lambda_3 * a_x)\n",
    "      b[i] = b_i - alpha * (-2 * err + 2 * lambda_4 * b_i)\n",
    "      V[i] = q_i - alpha * (-2 * err * p_x + 2 * lambda_1 * q_i)\n",
    "      U[x] = p_x - alpha * (-2 * err * q_i + 2 * lambda_2 * p_x)\n",
    "\n",
    "   J_history[iter] = cost_function(train_rating, U, V, lambda_1, lambda_2)\n",
    "\n",
    "print(\"final cost: \", cost_function(train_rating, U, V, lambda_1, lambda_2))\n",
    "plt.scatter(range(iters), J_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.59058602 3.85406441 2.45302439 ... 4.54547534 4.15502628 3.54059859] [4 4 3 ... 5 1 3]\n",
      "train_rmse=0.790, valid_rmse=0.950\n"
     ]
    }
   ],
   "source": [
    "train_predictions = predict(mu, train_user, train_movie)\n",
    "valid_predictions = predict(mu, valid_user, valid_movie)\n",
    "\n",
    "print(train_predictions, train_rating)\n",
    "\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "\n",
    "print('train_rmse=%.3f, valid_rmse=%.3f' % (train_rmse, valid_rmse))\n",
    "\n",
    "############################################\n",
    "# Testing\n",
    "############################################\n",
    "\n",
    "# Make and save predictions for test set\n",
    "test_predictions = predict(mu, test_user, test_movie)\n",
    "np.savetxt('test_predictions.txt', test_predictions)\n",
    "np.savetxt('d.txt', [nDims])\n",
    "np.savetxt('mu.txt', [mu])\n",
    "np.savetxt('u.txt', U)\n",
    "np.savetxt('v.txt', V)\n",
    "np.savetxt('a.txt', a)\n",
    "np.savetxt('b.txt', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Material: Inspect Predictions for Different Users\n",
    "\n",
    "After you have learned a good model, you may wish to interpret what it has learned. We can do this by looking at the most positive and most negative predictions for different users\n",
    "(or the movies that are bumped up or down from the baseline the most).\n",
    "\n",
    "Read and run the code below to see if you can understand the predictions. (Note: the predictions won't make sense until you have learned a good model!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "9c3800be-12ec-43a7-b24a-8cf543daf831"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User 0 ***\n",
      "  Top movies\n",
      "    +1.3545  Maya Lin: A Strong Clear Vision (1994)\n",
      "    +1.3061  Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "    +1.2943  Paths of Glory (1957)\n",
      "    +1.2533  Big Lebowski, The (1998)\n",
      "    +1.2524  Saint of Fort Washington, The (1993)\n",
      "    +1.2325  Kaspar Hauser (1993)\n",
      "    +1.2316  Wrong Trousers, The (1993)\n",
      "    +1.1870  Ghost in the Shell (Kokaku kidotai) (1995)\n",
      "\n",
      "  Bottom movies\n",
      "    -2.5442  Free Willy 3: The Rescue (1997)\n",
      "    -2.3746  Simple Wish, A (1997)\n",
      "    -2.3705  Showgirls (1995)\n",
      "    -2.2924  Original Gangstas (1996)\n",
      "    -2.2577  Jack and Sarah (1995)\n",
      "    -2.1824  Pest, The (1997)\n",
      "    -2.1628  Amityville II: The Possession (1982)\n",
      "    -2.1412  Home Alone 3 (1997)\n",
      "\n",
      "*** User 1 ***\n",
      "  Top movies\n",
      "    +1.4201  Delta of Venus (1994)\n",
      "    +1.4139  Bread and Chocolate (Pane e cioccolata) (1973)\n",
      "    +1.3489  Pather Panchali (1955)\n",
      "    +1.3205  Ruling Class, The (1972)\n",
      "    +1.3093  They Made Me a Criminal (1939)\n",
      "    +1.2671  Casablanca (1942)\n",
      "    +1.2601  Close Shave, A (1995)\n",
      "    +1.2509  Burnt By the Sun (1994)\n",
      "\n",
      "  Bottom movies\n",
      "    -2.1757  Bio-Dome (1996)\n",
      "    -2.0800  Simple Wish, A (1997)\n",
      "    -2.0533  New Age, The (1994)\n",
      "    -2.0480  Vampire in Brooklyn (1995)\n",
      "    -1.9930  Wild Things (1998)\n",
      "    -1.9844  Big Bully (1996)\n",
      "    -1.9530  Showgirls (1995)\n",
      "    -1.9514  Mr. Magoo (1997)\n",
      "\n",
      "*** User 2 ***\n",
      "  Top movies\n",
      "    +1.5903  Boys, Les (1997)\n",
      "    +1.4889  Saint of Fort Washington, The (1993)\n",
      "    +1.2475  Anna (1996)\n",
      "    +1.2154  Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "    +1.2093  Kaspar Hauser (1993)\n",
      "    +1.2081  Pather Panchali (1955)\n",
      "    +1.1749  Wrong Trousers, The (1993)\n",
      "    +1.1422  Godfather, The (1972)\n",
      "\n",
      "  Bottom movies\n",
      "    -2.8980  Free Willy 3: The Rescue (1997)\n",
      "    -2.8592  In the Army Now (1994)\n",
      "    -2.7899  Original Gangstas (1996)\n",
      "    -2.7874  Amityville II: The Possession (1982)\n",
      "    -2.7106  Amityville: A New Generation (1993)\n",
      "    -2.6459  White Man's Burden (1995)\n",
      "    -2.6121  Children of the Corn: The Gathering (1996)\n",
      "    -2.5823  Jack and Sarah (1995)\n",
      "\n",
      "*** User 3 ***\n",
      "  Top movies\n",
      "    +2.3728  Bad Taste (1987)\n",
      "    +2.2664  In the Line of Duty 2 (1987)\n",
      "    +1.9355  B*A*P*S (1997)\n",
      "    +1.9179  Madame Butterfly (1995)\n",
      "    +1.8353  Dunston Checks In (1996)\n",
      "    +1.8344  Withnail and I (1987)\n",
      "    +1.8077  Turbo: A Power Rangers Movie (1997)\n",
      "    +1.8018  Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\n",
      "\n",
      "  Bottom movies\n",
      "    -1.8043  Angel Baby (1995)\n",
      "    -1.7638  Police Story 4: Project S (Chao ji ji hua) (1993)\n",
      "    -1.4830  Radioland Murders (1994)\n",
      "    -1.3296  Simple Wish, A (1997)\n",
      "    -1.0886  Bastard Out of Carolina (1996)\n",
      "    -1.0856  Lost in Space (1998)\n",
      "    -1.0765  Striking Distance (1993)\n",
      "    -1.0535  Visitors, The (Visiteurs, Les) (1993)\n",
      "\n",
      "*** User 4 ***\n",
      "  Top movies\n",
      "    +1.7871  Boys, Les (1997)\n",
      "    +1.7575  Stalker (1979)\n",
      "    +1.6934  Paths of Glory (1957)\n",
      "    +1.6757  Ghost in the Shell (Kokaku kidotai) (1995)\n",
      "    +1.5015  Nico Icon (1995)\n",
      "    +1.4896  Big Lebowski, The (1998)\n",
      "    +1.4232  Kaspar Hauser (1993)\n",
      "    +1.4067  Living in Oblivion (1995)\n",
      "\n",
      "  Bottom movies\n",
      "    -3.3166  Free Willy 3: The Rescue (1997)\n",
      "    -2.9951  Original Gangstas (1996)\n",
      "    -2.8461  Pest, The (1997)\n",
      "    -2.8322  Jack and Sarah (1995)\n",
      "    -2.7997  Home Alone 3 (1997)\n",
      "    -2.7128  Amityville II: The Possession (1982)\n",
      "    -2.7040  In the Army Now (1994)\n",
      "    -2.6710  Switchback (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_movies = range(nMovies)\n",
    "\n",
    "\n",
    "def get_lowest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    return most_negative\n",
    "\n",
    "\n",
    "def get_highest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    most_positive = most_negative[::-1]\n",
    "    return most_positive\n",
    "\n",
    "\n",
    "k = 8\n",
    "all_users = range(nUsers)\n",
    "users_to_examine = all_users[0:5]\n",
    "\n",
    "for user in users_to_examine:\n",
    "\n",
    "    # Changes from baseline movie predictions for this user\n",
    "    delta = np.dot(V, U[user, :])\n",
    "\n",
    "    print('*** User %d ***' % (user))\n",
    "    print('  Top movies')\n",
    "    for i in get_highest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n",
    "\n",
    "    print('  Bottom movies')\n",
    "    for i in get_lowest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "496c99a6-522e-4637-aeda-aed1d27ea1a5"
    }
   },
   "source": [
    "## More Bonus Material: Interpretation of Weight Vectors as Features\n",
    "\n",
    "- So far we have described both $u_i$ and $v_j$ as _weight vectors_ (since we don't have any features of movies and users). But, it is possible to interpret one or both of these vectors as **learned features**.\n",
    "\n",
    "- For example, the first learned feature may discover a preference for comedy vs. drama. In this case:\n",
    "  - The user feature value $u_{i1}$ should be high if the user likes comedies and low if the user likes dramas better.\n",
    "  - The movie feature value $v_{j1}$ should be high if the movie is a comedy and low if it is a drama.\n",
    "- Similarly, feature 2 might describe whether a movie is geared toward kids or adults\n",
    "\n",
    "- In practice, the feature interpretations often find recognizable patterns but are not quite so clean to describe as the two examples above.\n",
    "\n",
    "Run the code below to examine the movies with the highest and lowest feature values for some of the features in your learned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "8d3aa776-2611-48aa-b921-84ff8f528fdf"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature 0 ***\n",
      "  Movies with highest feature value\n",
      "    +1.2044  Mostro, Il (1994)\n",
      "    +1.1609  Girl in the Cadillac (1995)\n",
      "    +1.1137  Sum of Us, The (1994)\n",
      "    +1.0947  Picture Bride (1995)\n",
      "    +1.0404  Angel Baby (1995)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.6198  Stupids, The (1996)\n",
      "    -1.5392  Endless Summer 2, The (1994)\n",
      "    -1.5151  Carried Away (1996)\n",
      "    -1.5146  Baby-Sitters Club, The (1995)\n",
      "    -1.4739  Phat Beach (1996)\n",
      "\n",
      "*** Feature 1 ***\n",
      "  Movies with highest feature value\n",
      "    +1.9352  Home Alone 3 (1997)\n",
      "    +1.7678  Wild Things (1998)\n",
      "    +1.6381  Bio-Dome (1996)\n",
      "    +1.6337  Vampire in Brooklyn (1995)\n",
      "    +1.5825  Lost in Space (1998)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.4549  Delta of Venus (1994)\n",
      "    -1.4096  Bread and Chocolate (Pane e cioccolata) (1973)\n",
      "    -1.3232  Aparajito (1956)\n",
      "    -1.2690  Carried Away (1996)\n",
      "    -1.2689  Ruling Class, The (1972)\n",
      "\n",
      "*** Feature 2 ***\n",
      "  Movies with highest feature value\n",
      "    +1.6366  Boys, Les (1997)\n",
      "    +0.9906  New York Cop (1996)\n",
      "    +0.9688  Angel Baby (1995)\n",
      "    +0.9586  Anna (1996)\n",
      "    +0.9439  Microcosmos: Le peuple de l'herbe (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -2.2556  In the Army Now (1994)\n",
      "    -1.9609  Castle Freak (1995)\n",
      "    -1.8833  Cutthroat Island (1995)\n",
      "    -1.8820  Sudden Manhattan (1996)\n",
      "    -1.8685  Temptress Moon (Feng Yue) (1996)\n",
      "\n",
      "*** Feature 3 ***\n",
      "  Movies with highest feature value\n",
      "    +1.8592  Amityville II: The Possession (1982)\n",
      "    +1.7986  Free Willy (1993)\n",
      "    +1.7781  Free Willy 3: The Rescue (1997)\n",
      "    +1.7312  Gone Fishin' (1997)\n",
      "    +1.6774  Jingle All the Way (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.2544  Ballad of Narayama, The (Narayama Bushiko) (1958)\n",
      "    -1.1099  Big Lebowski, The (1998)\n",
      "    -1.0837  Empire Strikes Back, The (1980)\n",
      "    -1.0570  Maya Lin: A Strong Clear Vision (1994)\n",
      "    -1.0436  Living in Oblivion (1995)\n",
      "\n",
      "*** Feature 4 ***\n",
      "  Movies with highest feature value\n",
      "    +1.3826  Of Human Bondage (1934)\n",
      "    +1.3171  Deceiver (1997)\n",
      "    +1.3066  Stalker (1979)\n",
      "    +1.1286  Lost in Space (1998)\n",
      "    +1.0289  Kicking and Screaming (1995)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -2.2744  In the Line of Duty 2 (1987)\n",
      "    -1.9596  Bad Taste (1987)\n",
      "    -1.6816  Kansas City (1996)\n",
      "    -1.5994  World of Apu, The (Apur Sansar) (1959)\n",
      "    -1.5430  Mostro, Il (1994)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "features_to_examine = np.arange(0, nDims)\n",
    "\n",
    "for feature in features_to_examine:\n",
    "\n",
    "    feature_vals = V[:, feature]\n",
    "\n",
    "    print('*** Feature %d ***' % (feature))\n",
    "    print('  Movies with highest feature value')\n",
    "    for i in get_highest(feature_vals)[0:k]:\n",
    "        print('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print('')\n",
    "\n",
    "    print('  Movies with lowest feature value')\n",
    "    for i in get_lowest(feature_vals)[0:k]:\n",
    "        print('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print('')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "d079999a1d0913a71f8d5b6eddecbf76a979d3a62d4116c9cf1961593761e2bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbpresent": {
   "slides": {
    "05dbf5c6-7ed4-44ff-96f5-22c560339a47": {
     "id": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "prev": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "regions": {
      "358609c2-5fc6-4b0e-b715-31776580497e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "48faf9e3-be4a-4ec4-888e-8ead4e2c67c5",
        "part": "whole"
       },
       "id": "358609c2-5fc6-4b0e-b715-31776580497e"
      }
     }
    },
    "1d9a4715-a031-4de3-8d97-d9e6066a461a": {
     "id": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "prev": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "regions": {
      "614fb7ec-54e5-4de3-bea3-88bec20b51e5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597ff142-4663-4ddb-bc6f-7b71e1127cc0",
        "part": "whole"
       },
       "id": "614fb7ec-54e5-4de3-bea3-88bec20b51e5"
      }
     }
    },
    "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c": {
     "id": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "prev": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "regions": {
      "36d74c3a-a835-4358-8199-45dbc6d3cbef": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c743c2d0-2dc4-4101-881c-01053255f632",
        "part": "whole"
       },
       "id": "36d74c3a-a835-4358-8199-45dbc6d3cbef"
      }
     }
    },
    "31877341-3b03-4601-8c41-3eb99ba92ab1": {
     "id": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "prev": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "regions": {
      "80e23835-4849-412a-8a53-23214ed34dd4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "705be6bb-9f8a-4d0f-804b-3c69c1a65bc9",
        "part": "whole"
       },
       "id": "80e23835-4849-412a-8a53-23214ed34dd4"
      }
     }
    },
    "42565e08-7bed-422d-a675-eb7334ca0ab5": {
     "id": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "prev": null,
     "regions": {
      "156465b7-096d-45d2-8bcf-7b00a992a68b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bd219f5b-9c65-4402-94f0-5e1933cc040f",
        "part": "whole"
       },
       "id": "156465b7-096d-45d2-8bcf-7b00a992a68b"
      }
     }
    },
    "60b8b15e-5b75-4c66-906d-f1d5ac44c63b": {
     "id": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "prev": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "regions": {
      "66cbb4cc-e38d-43e5-bff5-56c0c06fb651": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "496c99a6-522e-4637-aeda-aed1d27ea1a5",
        "part": "whole"
       },
       "id": "66cbb4cc-e38d-43e5-bff5-56c0c06fb651"
      }
     }
    },
    "68f4c6fe-5f2d-452d-835c-e3b7454d6b47": {
     "id": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "prev": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "regions": {
      "a5b4dede-9c3b-41d5-a601-171e4252eec5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "33f22eff-c565-4acc-bd8d-5d40678cb1e5",
        "part": "whole"
       },
       "id": "a5b4dede-9c3b-41d5-a601-171e4252eec5"
      }
     }
    },
    "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc": {
     "id": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "prev": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "regions": {
      "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "417fa0e4-6c70-4b9f-a42c-876215db961d",
        "part": "whole"
       },
       "id": "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7"
      }
     }
    },
    "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c": {
     "id": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "prev": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "regions": {
      "815ef0da-e3b6-488a-ac14-d837eecd3350": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534",
        "part": "whole"
       },
       "id": "815ef0da-e3b6-488a-ac14-d837eecd3350"
      }
     }
    },
    "99838ed2-6577-4917-a98b-5b45dbaff5b7": {
     "id": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "prev": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "regions": {
      "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2563258b-b1cb-45a3-baea-d0a9916e9f3a",
        "part": "whole"
       },
       "id": "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253"
      }
     }
    },
    "b75ebba2-4536-45b6-b14d-734821fc6db5": {
     "id": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "prev": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "regions": {
      "5b3123b6-b849-478a-b415-01dc4c7b8ddd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e6383de-b56e-4b0c-9173-05600260e586",
        "part": "whole"
       },
       "id": "5b3123b6-b849-478a-b415-01dc4c7b8ddd"
      }
     }
    },
    "ba5277be-2e8f-42a4-b899-2eb098d503e2": {
     "id": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "prev": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "regions": {
      "6672c882-0f15-431e-94d2-a39fd1c95dec": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa",
        "part": "whole"
       },
       "id": "6672c882-0f15-431e-94d2-a39fd1c95dec"
      }
     }
    },
    "c3f0d508-e7d2-45a1-9b29-91275df5c422": {
     "id": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "prev": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "regions": {
      "73d6c89e-93a2-47e7-ba8b-7dcd08353421": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8d3aa776-2611-48aa-b921-84ff8f528fdf",
        "part": "whole"
       },
       "id": "73d6c89e-93a2-47e7-ba8b-7dcd08353421"
      }
     }
    },
    "ca0eefa6-4215-4a13-96d3-ac4d59f36016": {
     "id": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "prev": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "regions": {
      "89f3061f-b00c-48f3-8862-9285b3370f5f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46a5a100-4e08-43e9-a313-ea1a0f06d149",
        "part": "whole"
       },
       "id": "89f3061f-b00c-48f3-8862-9285b3370f5f"
      }
     }
    },
    "d5c7ab89-c212-42a0-9613-2ecac8650d14": {
     "id": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "prev": "e1542729-bc97-495f-ac40-08ddb992f600",
     "regions": {
      "6b68aff0-cfbb-48a8-86fb-7a70448e8536": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f68ec3c-1530-4569-abd9-306b981a638b",
        "part": "whole"
       },
       "id": "6b68aff0-cfbb-48a8-86fb-7a70448e8536"
      }
     }
    },
    "e1542729-bc97-495f-ac40-08ddb992f600": {
     "id": "e1542729-bc97-495f-ac40-08ddb992f600",
     "prev": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "regions": {
      "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad3301d3-5e9b-4f82-8180-9410aa5fd885",
        "part": "whole"
       },
       "id": "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d"
      }
     }
    },
    "efe59041-9754-46cd-9a6f-a04eb76ccbbf": {
     "id": "efe59041-9754-46cd-9a6f-a04eb76ccbbf",
     "prev": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "regions": {
      "7c0bb904-8702-44bd-b57b-75e61e7a5a80": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "75676a65-f58b-4f20-b4a0-1cf8f1156d71",
        "part": "whole"
       },
       "id": "7c0bb904-8702-44bd-b57b-75e61e7a5a80"
      }
     }
    },
    "f0743c29-abc3-44be-87d6-dd1d5510322d": {
     "id": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "prev": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "regions": {
      "b058597c-5656-42c4-ae9e-74e567a11d40": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c",
        "part": "whole"
       },
       "id": "b058597c-5656-42c4-ae9e-74e567a11d40"
      }
     }
    },
    "f2a530ec-9ccc-485b-b61b-a99a778bbcba": {
     "id": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "prev": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "regions": {
      "3f7d423c-0b12-4667-886f-b8c5a8b455de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25aa92a1-20c9-4206-9133-ab31f96cb321",
        "part": "whole"
       },
       "id": "3f7d423c-0b12-4667-886f-b8c5a8b455de"
      }
     }
    },
    "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25": {
     "id": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "prev": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "regions": {
      "66fe2eda-b793-476d-989b-7eeca28e1890": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9c3800be-12ec-43a7-b24a-8cf543daf831",
        "part": "whole"
       },
       "id": "66fe2eda-b793-476d-989b-7eeca28e1890"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
